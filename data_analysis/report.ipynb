{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a7d8990-88c3-48e5-b735-d26dcfae46f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5e2b1c7-3539-42e9-882a-5f2860382b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"CNN-DailyMail\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2c8f2ae9-a440-4a20-a24d-103c236aa2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Treatment\n",
    "df_deepseek_1_5b = pd.read_csv(f\"./{dataset_name}/Treatment/results_deepseek-ai_DeepSeek-R1-Distill-Qwen-1.5B_{dataset_name}.csv\")\n",
    "\n",
    "df_gpt_neo_125m = pd.read_csv(f\"./{dataset_name}/Treatment/results_EleutherAI_gpt-neo-125m_{dataset_name}.csv\")\n",
    "df_gpt_neo_1_3b = pd.read_csv(f\"./{dataset_name}/Treatment/results_EleutherAI_gpt-neo-1.3B_{dataset_name}.csv\")\n",
    "df_gpt_neo_2_7b = pd.read_csv(f\"./{dataset_name}/Treatment/results_EleutherAI_gpt-neo-2.7B_{dataset_name}.csv\")\n",
    "\n",
    "df_opt_125m = pd.read_csv(f\"./{dataset_name}/Treatment/results_facebook_opt-125m_{dataset_name}.csv\")\n",
    "df_opt_1_3b = pd.read_csv(f\"./{dataset_name}/Treatment/results_facebook_opt-1.3b_{dataset_name}.csv\")\n",
    "# df_opt_350m = pd.read_csv(f\"./{dataset_name}/Treatment/results_facebook_opt-350m_{dataset_name}.csv\")\n",
    "df_opt_2_7b = pd.read_csv(f\"./{dataset_name}/Treatment/results_facebook_opt-2.7b_{dataset_name}.csv\")\n",
    "df_opt_6_7b = pd.read_csv(f\"./{dataset_name}/Treatment/results_facebook_opt-6.7b_{dataset_name}.csv\")\n",
    "\n",
    "df_vicuna_7b = pd.read_csv(f\"./{dataset_name}/Treatment/results_lmsys_vicuna-7b-v1.5_{dataset_name}.csv\")\n",
    "\n",
    "# # Control\n",
    "df_smol_1_7b = pd.read_csv(f\"./{dataset_name}/Control/results_HuggingFaceTB_SmolLM2-1.7B-Instruct_{dataset_name}.csv\")\n",
    "df_smol_135m = pd.read_csv(f\"./{dataset_name}/Control/results_HuggingFaceTB_SmolLM2-135M-Instruct_{dataset_name}.csv\")\n",
    "df_smol_360m = pd.read_csv(f\"./{dataset_name}/Control/results_HuggingFaceTB_SmolLM2-360M-Instruct_{dataset_name}.csv\")\n",
    "\n",
    "df_phi_3_5 = pd.read_csv(f\"./{dataset_name}/Control/results_microsoft_Phi-3.5-mini-instruct_{dataset_name}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4041f584-7d8c-4eb5-b3d2-7ad2c9e6990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {\n",
    "    \"df_deepseek_1_5b\": df_deepseek_1_5b,\n",
    "    \"df_gpt_neo_1_3b\": df_gpt_neo_1_3b,\n",
    "    \"df_gpt_neo_125m\": df_gpt_neo_125m,\n",
    "    \"df_gpt_neo_2_7b\": df_gpt_neo_2_7b,\n",
    "    \"df_opt_1_3b\": df_opt_1_3b,\n",
    "    \"df_opt_125m\": df_opt_125m,\n",
    "    \"df_opt_2_7b\": df_opt_2_7b,\n",
    "    # \"df_opt_350m\": df_opt_350m,\n",
    "    \"df_opt_6_7b\": df_opt_6_7b,\n",
    "    \"df_vicuna_7b\": df_vicuna_7b,\n",
    "    \"df_smol_1_7b\": df_smol_1_7b,\n",
    "    \"df_smol_135m\": df_smol_135m,\n",
    "    \"df_smol_360m\": df_smol_360m,\n",
    "    \"df_phi_3_5\": df_phi_3_5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "193cabdf-6538-4991-9ba2-fd3c0031e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "control = [\"df_smol_135m\", \"df_smol_360m\", \"df_smol_1_7b\"]\n",
    "contam = [\"df_gpt_neo_125m\", \"df_opt_125m\"]\n",
    "gpt = [\"df_gpt_neo_1_3b\", \"df_gpt_neo_2_7b\"]\n",
    "opt = [\"df_opt_1_3b\", \"df_opt_2_7b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d0057a9-5053-4c77-ac4d-01d5313a739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_opt_1_3b 40\n",
      "avg: 6.5608\n",
      "std: 0.8961\n",
      "df_opt_2_7b 40\n",
      "avg: 6.4361\n",
      "std: 0.8948\n",
      "df_opt_1_3b 50\n",
      "avg: 5.8431\n",
      "std: 0.8383\n",
      "df_opt_2_7b 50\n",
      "avg: 5.7193\n",
      "std: 0.8321\n"
     ]
    }
   ],
   "source": [
    "k_values = [\"40\", \"50\"]\n",
    "\n",
    "for k in k_values:\n",
    "    for model in opt:\n",
    "        print(model, k)\n",
    "        temp = dfs[model]\n",
    "        avg = round(temp['Min_{}.0%_Prob'.format(k)].mean(), 4)\n",
    "        sd = round(temp['Min_{}.0%_Prob'.format(k)].std(), 4)\n",
    "        print(\"avg: {}\".format(avg))\n",
    "        print(\"std: {}\".format(sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b54be1cb-87d5-46a2-9834-360b3217fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt_pairs = pd.read_csv(f\"./t_test/{dataset_name}/gpt_neo_.csv\")\n",
    "df_opt_pairs = pd.read_csv(f\"./t_test/{dataset_name}/opt.csv\")\n",
    "df_smol_pairs = pd.read_csv(f\"./t_test/{dataset_name}/smol.csv\")\n",
    "df_sus_con_pairs = pd.read_csv(f\"./t_test/{dataset_name}/sus_con_compare.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bab9727b-8ccc-412a-849a-a155335ea5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cos_sim_scores</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>rouge1_precision</th>\n",
       "      <th>rouge1_recall</th>\n",
       "      <th>rouge1_f1</th>\n",
       "      <th>rouge2_precision</th>\n",
       "      <th>rouge2_recall</th>\n",
       "      <th>rouge2_f1</th>\n",
       "      <th>rougeL_precision</th>\n",
       "      <th>rougeL_recall</th>\n",
       "      <th>rougeL_f1</th>\n",
       "      <th>Min_10.0%_Prob</th>\n",
       "      <th>Min_20.0%_Prob</th>\n",
       "      <th>Min_30.0%_Prob</th>\n",
       "      <th>Min_40.0%_Prob</th>\n",
       "      <th>Min_50.0%_Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>df_opt_125m vs df_opt_1_3b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1, 0.3202, 0.3046</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1, 0.0659, 0.0554</td>\n",
       "      <td>0</td>\n",
       "      <td>1, 0.0763, 0.0725</td>\n",
       "      <td>1, 0.237, 0.223</td>\n",
       "      <td>1, 0.1123, 0.1067</td>\n",
       "      <td>1, 10.6789, 9.9729</td>\n",
       "      <td>1, 9.1591, 8.4635</td>\n",
       "      <td>1, 8.1367, 7.4101</td>\n",
       "      <td>1, 7.299, 6.5608</td>\n",
       "      <td>1, 6.5758, 5.8431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df_opt_125m vs df_opt_2_7b</td>\n",
       "      <td>1, 0.3512, 0.2681</td>\n",
       "      <td>0</td>\n",
       "      <td>1, 0.103, 0.083</td>\n",
       "      <td>1, 0.3202, 0.26</td>\n",
       "      <td>1, 0.1516, 0.123</td>\n",
       "      <td>1, 0.0196, 0.0125</td>\n",
       "      <td>1, 0.0659, 0.043</td>\n",
       "      <td>1, 0.0295, 0.019</td>\n",
       "      <td>1, 0.0763, 0.0619</td>\n",
       "      <td>1, 0.237, 0.1934</td>\n",
       "      <td>1, 0.1123, 0.0916</td>\n",
       "      <td>1, 10.6789, 9.888</td>\n",
       "      <td>1, 9.1591, 8.3558</td>\n",
       "      <td>1, 8.1367, 7.2874</td>\n",
       "      <td>1, 7.299, 6.4361</td>\n",
       "      <td>1, 6.5758, 5.7193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>df_opt_125m vs df_opt_6_7b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1, 10.6789, 9.8428</td>\n",
       "      <td>1, 9.1591, 8.2642</td>\n",
       "      <td>1, 8.1367, 7.1724</td>\n",
       "      <td>1, 7.299, 6.3129</td>\n",
       "      <td>1, 6.5758, 5.5908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>df_opt_1_3b vs df_opt_2_7b</td>\n",
       "      <td>1, 0.337, 0.2681</td>\n",
       "      <td>0</td>\n",
       "      <td>1, 0.0986, 0.083</td>\n",
       "      <td>1, 0.3046, 0.26</td>\n",
       "      <td>1, 0.1454, 0.123</td>\n",
       "      <td>1, 0.0171, 0.0125</td>\n",
       "      <td>1, 0.0554, 0.043</td>\n",
       "      <td>1, 0.0255, 0.019</td>\n",
       "      <td>1, 0.0725, 0.0619</td>\n",
       "      <td>1, 0.223, 0.1934</td>\n",
       "      <td>1, 0.1067, 0.0916</td>\n",
       "      <td>0</td>\n",
       "      <td>1, 8.4635, 8.3558</td>\n",
       "      <td>1, 7.4101, 7.2874</td>\n",
       "      <td>1, 6.5608, 6.4361</td>\n",
       "      <td>1, 5.8431, 5.7193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df_opt_1_3b vs df_opt_6_7b</td>\n",
       "      <td>1, 0.337, 0.366</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1, 0.3046, 0.3268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1, 0.0554, 0.0693</td>\n",
       "      <td>1, 0.0255, 0.0298</td>\n",
       "      <td>0</td>\n",
       "      <td>1, 0.223, 0.2408</td>\n",
       "      <td>0</td>\n",
       "      <td>1, 9.9729, 9.8428</td>\n",
       "      <td>1, 8.4635, 8.2642</td>\n",
       "      <td>1, 7.4101, 7.1724</td>\n",
       "      <td>1, 6.5608, 6.3129</td>\n",
       "      <td>1, 5.8431, 5.5908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>df_opt_2_7b vs df_opt_6_7b</td>\n",
       "      <td>1, 0.2681, 0.366</td>\n",
       "      <td>0</td>\n",
       "      <td>1, 0.083, 0.0993</td>\n",
       "      <td>1, 0.26, 0.3268</td>\n",
       "      <td>1, 0.123, 0.1484</td>\n",
       "      <td>1, 0.0125, 0.0196</td>\n",
       "      <td>1, 0.043, 0.0693</td>\n",
       "      <td>1, 0.019, 0.0298</td>\n",
       "      <td>1, 0.0619, 0.073</td>\n",
       "      <td>1, 0.1934, 0.2408</td>\n",
       "      <td>1, 0.0916, 0.1091</td>\n",
       "      <td>0</td>\n",
       "      <td>1, 8.3558, 8.2642</td>\n",
       "      <td>1, 7.2874, 7.1724</td>\n",
       "      <td>1, 6.4361, 6.3129</td>\n",
       "      <td>1, 5.7193, 5.5908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Unnamed: 0     cos_sim_scores  levenshtein_distance  \\\n",
       "0  df_opt_125m vs df_opt_1_3b                  0                     0   \n",
       "1  df_opt_125m vs df_opt_2_7b  1, 0.3512, 0.2681                     0   \n",
       "2  df_opt_125m vs df_opt_6_7b                  0                     0   \n",
       "3  df_opt_1_3b vs df_opt_2_7b   1, 0.337, 0.2681                     0   \n",
       "4  df_opt_1_3b vs df_opt_6_7b    1, 0.337, 0.366                     0   \n",
       "5  df_opt_2_7b vs df_opt_6_7b   1, 0.2681, 0.366                     0   \n",
       "\n",
       "   rouge1_precision      rouge1_recall         rouge1_f1   rouge2_precision  \\\n",
       "0                 0  1, 0.3202, 0.3046                 0                  0   \n",
       "1   1, 0.103, 0.083    1, 0.3202, 0.26  1, 0.1516, 0.123  1, 0.0196, 0.0125   \n",
       "2                 0                  0                 0                  0   \n",
       "3  1, 0.0986, 0.083    1, 0.3046, 0.26  1, 0.1454, 0.123  1, 0.0171, 0.0125   \n",
       "4                 0  1, 0.3046, 0.3268                 0                  0   \n",
       "5  1, 0.083, 0.0993    1, 0.26, 0.3268  1, 0.123, 0.1484  1, 0.0125, 0.0196   \n",
       "\n",
       "       rouge2_recall          rouge2_f1   rougeL_precision      rougeL_recall  \\\n",
       "0  1, 0.0659, 0.0554                  0  1, 0.0763, 0.0725    1, 0.237, 0.223   \n",
       "1   1, 0.0659, 0.043   1, 0.0295, 0.019  1, 0.0763, 0.0619   1, 0.237, 0.1934   \n",
       "2                  0                  0                  0                  0   \n",
       "3   1, 0.0554, 0.043   1, 0.0255, 0.019  1, 0.0725, 0.0619   1, 0.223, 0.1934   \n",
       "4  1, 0.0554, 0.0693  1, 0.0255, 0.0298                  0   1, 0.223, 0.2408   \n",
       "5   1, 0.043, 0.0693   1, 0.019, 0.0298   1, 0.0619, 0.073  1, 0.1934, 0.2408   \n",
       "\n",
       "           rougeL_f1      Min_10.0%_Prob     Min_20.0%_Prob  \\\n",
       "0  1, 0.1123, 0.1067  1, 10.6789, 9.9729  1, 9.1591, 8.4635   \n",
       "1  1, 0.1123, 0.0916   1, 10.6789, 9.888  1, 9.1591, 8.3558   \n",
       "2                  0  1, 10.6789, 9.8428  1, 9.1591, 8.2642   \n",
       "3  1, 0.1067, 0.0916                   0  1, 8.4635, 8.3558   \n",
       "4                  0   1, 9.9729, 9.8428  1, 8.4635, 8.2642   \n",
       "5  1, 0.0916, 0.1091                   0  1, 8.3558, 8.2642   \n",
       "\n",
       "      Min_30.0%_Prob     Min_40.0%_Prob     Min_50.0%_Prob  \n",
       "0  1, 8.1367, 7.4101   1, 7.299, 6.5608  1, 6.5758, 5.8431  \n",
       "1  1, 8.1367, 7.2874   1, 7.299, 6.4361  1, 6.5758, 5.7193  \n",
       "2  1, 8.1367, 7.1724   1, 7.299, 6.3129  1, 6.5758, 5.5908  \n",
       "3  1, 7.4101, 7.2874  1, 6.5608, 6.4361  1, 5.8431, 5.7193  \n",
       "4  1, 7.4101, 7.1724  1, 6.5608, 6.3129  1, 5.8431, 5.5908  \n",
       "5  1, 7.2874, 7.1724  1, 6.4361, 6.3129  1, 5.7193, 5.5908  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_opt_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8ba1cb3-50e1-481d-8257-0e6931466125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c24b9903-a5d5-4407-9c32-d3106d325b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {\"Model_Responses\": \"\"}\n",
    "for model in dfs:\n",
    "    # dfs[model].fillna(value=values, inplace=True)\n",
    "    dfs[model].dropna(subset=[\"Model_Responses\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca30e4-328c-4898-b842-2523ca1c9a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd2cbd3b-b1ea-48f7-854e-f70a784386ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_deepseek_1_5b\n",
      "response avg. length 18.21392313270486\n",
      "gold avg. length 57.83031182015954\n",
      "df_gpt_neo_1_3b\n",
      "response avg. length 17.68580060422961\n",
      "gold avg. length 57.85649546827795\n",
      "df_gpt_neo_125m\n",
      "response avg. length 18.008358662613983\n",
      "gold avg. length 58.56838905775076\n",
      "df_gpt_neo_2_7b\n",
      "response avg. length 17.526555386949923\n",
      "gold avg. length 57.97572078907435\n",
      "df_opt_1_3b\n",
      "response avg. length 17.495644599303137\n",
      "gold avg. length 57.90940766550523\n",
      "df_opt_125m\n",
      "response avg. length 17.332451499118164\n",
      "gold avg. length 58.7010582010582\n",
      "df_opt_2_7b\n",
      "response avg. length 17.631753948462176\n",
      "gold avg. length 58.05403158769742\n",
      "df_opt_6_7b\n",
      "response avg. length 16.938755020080322\n",
      "gold avg. length 58.90963855421687\n",
      "df_vicuna_7b\n",
      "response avg. length 206.136460554371\n",
      "gold avg. length 62.59061833688699\n",
      "df_smol_1_7b\n",
      "response avg. length 12.982596084118926\n",
      "gold avg. length 57.83031182015954\n",
      "df_smol_135m\n",
      "response avg. length 13.29245283018868\n",
      "gold avg. length 58.67561683599419\n",
      "df_smol_360m\n",
      "response avg. length 13.08411892675852\n",
      "gold avg. length 58.68455402465555\n",
      "df_phi_3_5\n",
      "response avg. length 14.749818709209572\n",
      "gold avg. length 57.661348803480784\n"
     ]
    }
   ],
   "source": [
    "for model in dfs:\n",
    "    print(model)\n",
    "    out = dfs[model].Model_Responses.apply(word_tokenize).apply(len)\n",
    "    gold = dfs[model].Gold_Labels.apply(word_tokenize).apply(len)\n",
    "    \n",
    "    print(\"response avg. length {}\".format(out.mean()))\n",
    "    print(\"gold avg. length {}\".format(gold.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62d6b0f5-26e3-4a17-b685-0da281bfb857",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_names = df_deepseek_1_5b.drop(['Unnamed: 0', 'Model', 'Task_Prefix', 'Dataset_Name', 'Model_Responses', 'Gold_Labels'], axis=1).columns\n",
    "score_names = list(score_names)\n",
    "gpt = [\"df_gpt_neo_125m\", \"df_gpt_neo_1_3b\", \"df_gpt_neo_2_7b\"]\n",
    "# opt = [\"df_opt_125m\", \"df_opt_350m\", \"df_opt_1_3b\", \"df_opt_2_7b\", \"df_opt_6_7b\"]\n",
    "opt = [\"df_opt_125m\", \"df_opt_1_3b\", \"df_opt_2_7b\", \"df_opt_6_7b\"]\n",
    "vicuna = [\"df_vicuna_7b\"]\n",
    "smol = [\"df_smol_135m\", \"df_smol_360m\", \"df_smol_1_7b\"]\n",
    "phi = [\"df_phi_3_5\"]\n",
    "treatment = gpt + opt + vicuna\n",
    "control = smol + phi\n",
    "small = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ce02b2-f36a-42bd-86ca-dcc3f395339b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>cos sim scores</th>\n",
       "      <th>levenshtein distance</th>\n",
       "      <th>rouge1 precision</th>\n",
       "      <th>rouge1 recall</th>\n",
       "      <th>rouge1 f1</th>\n",
       "      <th>rouge2 precision</th>\n",
       "      <th>rouge2 recall</th>\n",
       "      <th>rouge2 f1</th>\n",
       "      <th>rougeL precision</th>\n",
       "      <th>rougeL recall</th>\n",
       "      <th>rougeL f1</th>\n",
       "      <th>Min 10.0% Prob</th>\n",
       "      <th>Min 20.0% Prob</th>\n",
       "      <th>Min 30.0% Prob</th>\n",
       "      <th>Min 40.0% Prob</th>\n",
       "      <th>Min 50.0% Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt neo 125m</td>\n",
       "      <td>0.3674±0.1861</td>\n",
       "      <td>261.8818±146.6581</td>\n",
       "      <td>0.1081±0.0659</td>\n",
       "      <td>0.329±0.1959</td>\n",
       "      <td>0.1587±0.092</td>\n",
       "      <td>0.0221±0.0389</td>\n",
       "      <td>0.0718±0.1253</td>\n",
       "      <td>0.0329±0.0566</td>\n",
       "      <td>0.081±0.0514</td>\n",
       "      <td>0.2458±0.1512</td>\n",
       "      <td>0.1187±0.0712</td>\n",
       "      <td>10.8609±1.098</td>\n",
       "      <td>9.4261±0.9349</td>\n",
       "      <td>8.4367±0.8816</td>\n",
       "      <td>7.6085±0.8495</td>\n",
       "      <td>6.8797±0.8114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt neo 1 3b</td>\n",
       "      <td>0.3611±0.1892</td>\n",
       "      <td>257.3952±103.7787</td>\n",
       "      <td>0.1059±0.0639</td>\n",
       "      <td>0.3257±0.1865</td>\n",
       "      <td>0.1562±0.0895</td>\n",
       "      <td>0.0212±0.0373</td>\n",
       "      <td>0.0687±0.1183</td>\n",
       "      <td>0.0317±0.0547</td>\n",
       "      <td>0.0776±0.0482</td>\n",
       "      <td>0.2382±0.1408</td>\n",
       "      <td>0.1143±0.0674</td>\n",
       "      <td>10.1481±1.1905</td>\n",
       "      <td>8.6304±1.0137</td>\n",
       "      <td>7.5887±0.9549</td>\n",
       "      <td>6.742±0.8984</td>\n",
       "      <td>6.017±0.8417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt neo 2 7b</td>\n",
       "      <td>0.364±0.1962</td>\n",
       "      <td>257.897±104.3836</td>\n",
       "      <td>0.1057±0.0649</td>\n",
       "      <td>0.3265±0.1921</td>\n",
       "      <td>0.1559±0.0911</td>\n",
       "      <td>0.0211±0.0359</td>\n",
       "      <td>0.069±0.1173</td>\n",
       "      <td>0.0315±0.0529</td>\n",
       "      <td>0.0781±0.0502</td>\n",
       "      <td>0.2408±0.1471</td>\n",
       "      <td>0.115±0.0699</td>\n",
       "      <td>10.0165±1.1758</td>\n",
       "      <td>8.4883±1.0351</td>\n",
       "      <td>7.4307±0.9689</td>\n",
       "      <td>6.576±0.9027</td>\n",
       "      <td>5.8512±0.8379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opt 125m</td>\n",
       "      <td>0.3022±0.2027</td>\n",
       "      <td>270.1022±148.2328</td>\n",
       "      <td>0.0847±0.0684</td>\n",
       "      <td>0.2633±0.2065</td>\n",
       "      <td>0.1247±0.0972</td>\n",
       "      <td>0.0161±0.0332</td>\n",
       "      <td>0.0542±0.1077</td>\n",
       "      <td>0.0242±0.0485</td>\n",
       "      <td>0.0627±0.051</td>\n",
       "      <td>0.1949±0.1541</td>\n",
       "      <td>0.0923±0.0726</td>\n",
       "      <td>10.675±1.135</td>\n",
       "      <td>9.1528±0.9986</td>\n",
       "      <td>8.1265±0.9567</td>\n",
       "      <td>7.29±0.9134</td>\n",
       "      <td>6.5675±0.8699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opt 1 3b</td>\n",
       "      <td>0.2929±0.2038</td>\n",
       "      <td>265.6875±106.7315</td>\n",
       "      <td>0.0821±0.0672</td>\n",
       "      <td>0.2536±0.2036</td>\n",
       "      <td>0.1211±0.096</td>\n",
       "      <td>0.0142±0.0324</td>\n",
       "      <td>0.0462±0.1036</td>\n",
       "      <td>0.0212±0.0475</td>\n",
       "      <td>0.0603±0.05</td>\n",
       "      <td>0.1857±0.1509</td>\n",
       "      <td>0.0888±0.0712</td>\n",
       "      <td>9.9732±1.0737</td>\n",
       "      <td>8.4591±0.9956</td>\n",
       "      <td>7.4052±0.9463</td>\n",
       "      <td>6.5571±0.898</td>\n",
       "      <td>5.8374±0.8403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opt 2 7b</td>\n",
       "      <td>0.2426±0.2025</td>\n",
       "      <td>265.4714±105.6499</td>\n",
       "      <td>0.0724±0.0611</td>\n",
       "      <td>0.2268±0.1891</td>\n",
       "      <td>0.1073±0.0881</td>\n",
       "      <td>0.0109±0.0282</td>\n",
       "      <td>0.0375±0.0952</td>\n",
       "      <td>0.0165±0.0423</td>\n",
       "      <td>0.054±0.0454</td>\n",
       "      <td>0.1687±0.1411</td>\n",
       "      <td>0.0799±0.0654</td>\n",
       "      <td>9.8604±1.0795</td>\n",
       "      <td>8.3292±1.0114</td>\n",
       "      <td>7.263±0.9569</td>\n",
       "      <td>6.4135±0.903</td>\n",
       "      <td>5.6969±0.8407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>opt 6 7b</td>\n",
       "      <td>0.2846±0.2039</td>\n",
       "      <td>271.2516±114.9079</td>\n",
       "      <td>0.0717±0.0661</td>\n",
       "      <td>0.2367±0.2073</td>\n",
       "      <td>0.1072±0.0954</td>\n",
       "      <td>0.0142±0.03</td>\n",
       "      <td>0.05±0.0992</td>\n",
       "      <td>0.0215±0.0445</td>\n",
       "      <td>0.0528±0.0498</td>\n",
       "      <td>0.1747±0.1573</td>\n",
       "      <td>0.0788±0.0718</td>\n",
       "      <td>9.8381±1.1061</td>\n",
       "      <td>8.2602±1.0252</td>\n",
       "      <td>7.1737±0.9596</td>\n",
       "      <td>6.3121±0.9034</td>\n",
       "      <td>5.5915±0.8455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vicuna 7b</td>\n",
       "      <td>0.2029±0.2289</td>\n",
       "      <td>550.5707±1570.2964</td>\n",
       "      <td>0.0807±0.159</td>\n",
       "      <td>0.0892±0.1594</td>\n",
       "      <td>0.0671±0.1168</td>\n",
       "      <td>0.0216±0.069</td>\n",
       "      <td>0.0204±0.0674</td>\n",
       "      <td>0.0161±0.0462</td>\n",
       "      <td>0.054±0.1076</td>\n",
       "      <td>0.0605±0.1133</td>\n",
       "      <td>0.0442±0.077</td>\n",
       "      <td>10.4488±1.0191</td>\n",
       "      <td>8.5177±0.9514</td>\n",
       "      <td>7.2157±0.9056</td>\n",
       "      <td>6.2002±0.8576</td>\n",
       "      <td>5.3611±0.8003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0 cos sim scores levenshtein distance rouge1 precision  \\\n",
       "0   gpt neo 125m  0.3674±0.1861    261.8818±146.6581    0.1081±0.0659   \n",
       "0   gpt neo 1 3b  0.3611±0.1892    257.3952±103.7787    0.1059±0.0639   \n",
       "0   gpt neo 2 7b   0.364±0.1962     257.897±104.3836    0.1057±0.0649   \n",
       "0       opt 125m  0.3022±0.2027    270.1022±148.2328    0.0847±0.0684   \n",
       "0       opt 1 3b  0.2929±0.2038    265.6875±106.7315    0.0821±0.0672   \n",
       "0       opt 2 7b  0.2426±0.2025    265.4714±105.6499    0.0724±0.0611   \n",
       "0       opt 6 7b  0.2846±0.2039    271.2516±114.9079    0.0717±0.0661   \n",
       "0      vicuna 7b  0.2029±0.2289   550.5707±1570.2964     0.0807±0.159   \n",
       "\n",
       "   rouge1 recall      rouge1 f1 rouge2 precision  rouge2 recall  \\\n",
       "0   0.329±0.1959   0.1587±0.092    0.0221±0.0389  0.0718±0.1253   \n",
       "0  0.3257±0.1865  0.1562±0.0895    0.0212±0.0373  0.0687±0.1183   \n",
       "0  0.3265±0.1921  0.1559±0.0911    0.0211±0.0359   0.069±0.1173   \n",
       "0  0.2633±0.2065  0.1247±0.0972    0.0161±0.0332  0.0542±0.1077   \n",
       "0  0.2536±0.2036   0.1211±0.096    0.0142±0.0324  0.0462±0.1036   \n",
       "0  0.2268±0.1891  0.1073±0.0881    0.0109±0.0282  0.0375±0.0952   \n",
       "0  0.2367±0.2073  0.1072±0.0954      0.0142±0.03    0.05±0.0992   \n",
       "0  0.0892±0.1594  0.0671±0.1168     0.0216±0.069  0.0204±0.0674   \n",
       "\n",
       "       rouge2 f1 rougeL precision  rougeL recall      rougeL f1  \\\n",
       "0  0.0329±0.0566     0.081±0.0514  0.2458±0.1512  0.1187±0.0712   \n",
       "0  0.0317±0.0547    0.0776±0.0482  0.2382±0.1408  0.1143±0.0674   \n",
       "0  0.0315±0.0529    0.0781±0.0502  0.2408±0.1471   0.115±0.0699   \n",
       "0  0.0242±0.0485     0.0627±0.051  0.1949±0.1541  0.0923±0.0726   \n",
       "0  0.0212±0.0475      0.0603±0.05  0.1857±0.1509  0.0888±0.0712   \n",
       "0  0.0165±0.0423     0.054±0.0454  0.1687±0.1411  0.0799±0.0654   \n",
       "0  0.0215±0.0445    0.0528±0.0498  0.1747±0.1573  0.0788±0.0718   \n",
       "0  0.0161±0.0462     0.054±0.1076  0.0605±0.1133   0.0442±0.077   \n",
       "\n",
       "   Min 10.0% Prob Min 20.0% Prob Min 30.0% Prob Min 40.0% Prob Min 50.0% Prob  \n",
       "0   10.8609±1.098  9.4261±0.9349  8.4367±0.8816  7.6085±0.8495  6.8797±0.8114  \n",
       "0  10.1481±1.1905  8.6304±1.0137  7.5887±0.9549   6.742±0.8984   6.017±0.8417  \n",
       "0  10.0165±1.1758  8.4883±1.0351  7.4307±0.9689   6.576±0.9027  5.8512±0.8379  \n",
       "0    10.675±1.135  9.1528±0.9986  8.1265±0.9567    7.29±0.9134  6.5675±0.8699  \n",
       "0   9.9732±1.0737  8.4591±0.9956  7.4052±0.9463   6.5571±0.898  5.8374±0.8403  \n",
       "0   9.8604±1.0795  8.3292±1.0114   7.263±0.9569   6.4135±0.903  5.6969±0.8407  \n",
       "0   9.8381±1.1061  8.2602±1.0252  7.1737±0.9596  6.3121±0.9034  5.5915±0.8455  \n",
       "0  10.4488±1.0191  8.5177±0.9514  7.2157±0.9056  6.2002±0.8576  5.3611±0.8003  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "col_namer = { i+1: s.replace(\"_\", \" \") for i, s in enumerate(score_names)}\n",
    "\n",
    "# loop over models in a group\n",
    "for model in treatment:\n",
    "    row = [model] # pre-pend row with model name\n",
    "    for score in score_names:\n",
    "        # add the average value for each metric for this model\n",
    "        metric = dfs[model].loc[:,score]\n",
    "        avg = round(metric.mean(), 4)\n",
    "        sd = round(metric.std(), 4)\n",
    "        row.append(\"{}±{}\".format(avg, sd))\n",
    "    temp = pd.DataFrame([row])\n",
    "    result = pd.concat([result, temp])\n",
    "\n",
    "# replace underscores and unnecessary symbols\n",
    "result = result.rename(columns=col_namer, index=lambda c: str(c).replace(\"_\", \" \"))\n",
    "result.iloc[:, 0] = result.iloc[:, 0].str.replace(\"_\", \" \").str.replace(\"df\", \"\").str.replace(\"%\", \"\\%\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "712b7cb4-eaa9-463c-b2c1-a427ade33055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllllllll}\n",
      "\\toprule\n",
      " & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
      "\\midrule\n",
      "0 &  gpt neo 125m &  gpt neo 1 3b &  gpt neo 2 7b &  opt 125m &  opt 1 3b &  opt 2 7b &  opt 6 7b &  vicuna 7b \\\\\n",
      "cos sim scores & 0.3674±0.1861 & 0.3611±0.1892 & 0.364±0.1962 & 0.3022±0.2027 & 0.2929±0.2038 & 0.2426±0.2025 & 0.2846±0.2039 & 0.2029±0.2289 \\\\\n",
      "levenshtein distance & 261.8818±146.6581 & 257.3952±103.7787 & 257.897±104.3836 & 270.1022±148.2328 & 265.6875±106.7315 & 265.4714±105.6499 & 271.2516±114.9079 & 550.5707±1570.2964 \\\\\n",
      "rouge1 precision & 0.1081±0.0659 & 0.1059±0.0639 & 0.1057±0.0649 & 0.0847±0.0684 & 0.0821±0.0672 & 0.0724±0.0611 & 0.0717±0.0661 & 0.0807±0.159 \\\\\n",
      "rouge1 recall & 0.329±0.1959 & 0.3257±0.1865 & 0.3265±0.1921 & 0.2633±0.2065 & 0.2536±0.2036 & 0.2268±0.1891 & 0.2367±0.2073 & 0.0892±0.1594 \\\\\n",
      "rouge1 f1 & 0.1587±0.092 & 0.1562±0.0895 & 0.1559±0.0911 & 0.1247±0.0972 & 0.1211±0.096 & 0.1073±0.0881 & 0.1072±0.0954 & 0.0671±0.1168 \\\\\n",
      "rouge2 precision & 0.0221±0.0389 & 0.0212±0.0373 & 0.0211±0.0359 & 0.0161±0.0332 & 0.0142±0.0324 & 0.0109±0.0282 & 0.0142±0.03 & 0.0216±0.069 \\\\\n",
      "rouge2 recall & 0.0718±0.1253 & 0.0687±0.1183 & 0.069±0.1173 & 0.0542±0.1077 & 0.0462±0.1036 & 0.0375±0.0952 & 0.05±0.0992 & 0.0204±0.0674 \\\\\n",
      "rouge2 f1 & 0.0329±0.0566 & 0.0317±0.0547 & 0.0315±0.0529 & 0.0242±0.0485 & 0.0212±0.0475 & 0.0165±0.0423 & 0.0215±0.0445 & 0.0161±0.0462 \\\\\n",
      "rougeL precision & 0.081±0.0514 & 0.0776±0.0482 & 0.0781±0.0502 & 0.0627±0.051 & 0.0603±0.05 & 0.054±0.0454 & 0.0528±0.0498 & 0.054±0.1076 \\\\\n",
      "rougeL recall & 0.2458±0.1512 & 0.2382±0.1408 & 0.2408±0.1471 & 0.1949±0.1541 & 0.1857±0.1509 & 0.1687±0.1411 & 0.1747±0.1573 & 0.0605±0.1133 \\\\\n",
      "rougeL f1 & 0.1187±0.0712 & 0.1143±0.0674 & 0.115±0.0699 & 0.0923±0.0726 & 0.0888±0.0712 & 0.0799±0.0654 & 0.0788±0.0718 & 0.0442±0.077 \\\\\n",
      "Min 10.0% Prob & 10.8609±1.098 & 10.1481±1.1905 & 10.0165±1.1758 & 10.675±1.135 & 9.9732±1.0737 & 9.8604±1.0795 & 9.8381±1.1061 & 10.4488±1.0191 \\\\\n",
      "Min 20.0% Prob & 9.4261±0.9349 & 8.6304±1.0137 & 8.4883±1.0351 & 9.1528±0.9986 & 8.4591±0.9956 & 8.3292±1.0114 & 8.2602±1.0252 & 8.5177±0.9514 \\\\\n",
      "Min 30.0% Prob & 8.4367±0.8816 & 7.5887±0.9549 & 7.4307±0.9689 & 8.1265±0.9567 & 7.4052±0.9463 & 7.263±0.9569 & 7.1737±0.9596 & 7.2157±0.9056 \\\\\n",
      "Min 40.0% Prob & 7.6085±0.8495 & 6.742±0.8984 & 6.576±0.9027 & 7.29±0.9134 & 6.5571±0.898 & 6.4135±0.903 & 6.3121±0.9034 & 6.2002±0.8576 \\\\\n",
      "Min 50.0% Prob & 6.8797±0.8114 & 6.017±0.8417 & 5.8512±0.8379 & 6.5675±0.8699 & 5.8374±0.8403 & 5.6969±0.8407 & 5.5915±0.8455 & 5.3611±0.8003 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print to get newliens\n",
    "# format floats here\n",
    "print(result.T.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
